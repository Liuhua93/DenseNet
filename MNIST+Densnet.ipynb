{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "# My model\n",
    "import DenseNet as dn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH = 1\n",
    "# train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 10\n",
    "LR = 0.001              # learning rate\n",
    "DOWNLOAD_MNIST = True   # set to False if you have downloaded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Normalize with the grayscale channel's mean and var\n",
    "#https://discuss.pytorch.org/t/normalization-in-the-mnist-example/457\n",
    "\n",
    "trainTransform = transforms.Compose([\n",
    "    transforms.RandomCrop(28, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "    \n",
    "testTransform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import DenseNet as dn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Mnist digits dataset\n",
    "train_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist/',\n",
    "    train=True,                                     # this is training data\n",
    "    transform=trainTransform,    # Converts a PIL.Image or numpy.ndarray to\n",
    "                                                    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]\n",
    "    download=DOWNLOAD_MNIST,                        # download it if you don't have it\n",
    ")\n",
    "\n",
    "\n",
    "# torchvision.datasets.MNIST(root='/home/ubuntu/notebooks/mnist', train=True)\n",
    "test_data = torchvision.datasets.MNIST(\n",
    "    root='./mnist/', \n",
    "    train=False,\n",
    "    transform = testTransform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([60000])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f68f2c54110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot one example\n",
    "print(train_data.train_data.size())                 # (60000, 28, 28)\n",
    "print(train_data.train_labels.size())               # (60000)\n",
    "plt.imshow(train_data.train_data[0].numpy(), cmap='gray')\n",
    "plt.title('%i' % train_data.train_labels[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# convert test data into Variable, pick 2000 samples to speed up testing\n",
    "# test_data = torchvision.datasets.MNIST(root='./mnist/', train=False,transform=testTransform)\n",
    "\n",
    "# Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_data, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True)\n",
    "\n",
    "testLoader = DataLoader(\n",
    "        dataset=test_data,\n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/feedback-on-pytorch-for-kaggle-competitions/2252/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = dn.DenseNet(num_init_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DenseNet (\n",
      "  (features): Sequential (\n",
      "    (conv0): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (norm0): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu0): ReLU (inplace)\n",
      "    (denseblock1): _DenseBlock (\n",
      "      (denselayer1): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(10, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(14, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(18, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(22, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(26, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(30, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition1): _Transition (\n",
      "      (norm): BatchNorm2d(34, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(34, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d (\n",
      "      )\n",
      "    )\n",
      "    (last_norm1): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (denseblock2): _DenseBlock (\n",
      "      (denselayer1): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(17, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(21, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(25, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(29, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(33, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(37, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(37, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (transition2): _Transition (\n",
      "      (norm): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True)\n",
      "      (relu): ReLU (inplace)\n",
      "      (conv): Conv2d(41, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (pool): AvgPool2d (\n",
      "      )\n",
      "    )\n",
      "    (last_norm2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (denseblock3): _DenseBlock (\n",
      "      (denselayer1): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(20, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer2): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer3): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(28, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer4): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer5): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(36, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (denselayer6): _DenseLayer (\n",
      "        (norm.1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (relu.1): ReLU (inplace)\n",
      "        (conv.1): Conv2d(40, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "        (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      )\n",
      "    )\n",
      "    (last_norm3): BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True)\n",
      "  )\n",
      "  (classifier): Linear (44 -> 10)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "EPOCH = 1\n",
    "# train the training data n times, to save time, we just train 1 epoch\n",
    "BATCH_SIZE = 50\n",
    "LR = 0.001              # learning rate\n",
    "optimizer = optim.SGD(model.parameters(), lr=LR,\n",
    "                            momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.325125\n",
      "Train Epoch: 0 [100/60000 (0%)]\tLoss: 2.245820\n",
      "Train Epoch: 0 [200/60000 (0%)]\tLoss: 2.179801\n",
      "Train Epoch: 0 [300/60000 (0%)]\tLoss: 2.255246\n",
      "Train Epoch: 0 [400/60000 (1%)]\tLoss: 2.120733\n",
      "Train Epoch: 0 [500/60000 (1%)]\tLoss: 2.163141\n",
      "Train Epoch: 0 [600/60000 (1%)]\tLoss: 2.027833\n",
      "Train Epoch: 0 [700/60000 (1%)]\tLoss: 2.003646\n",
      "Train Epoch: 0 [800/60000 (1%)]\tLoss: 1.876076\n",
      "Train Epoch: 0 [900/60000 (2%)]\tLoss: 1.865627\n",
      "Train Epoch: 0 [1000/60000 (2%)]\tLoss: 1.762607\n",
      "Train Epoch: 0 [1100/60000 (2%)]\tLoss: 1.958474\n",
      "Train Epoch: 0 [1200/60000 (2%)]\tLoss: 1.869174\n",
      "Train Epoch: 0 [1300/60000 (2%)]\tLoss: 1.808599\n",
      "Train Epoch: 0 [1400/60000 (2%)]\tLoss: 1.734255\n",
      "Train Epoch: 0 [1500/60000 (2%)]\tLoss: 1.657212\n",
      "Train Epoch: 0 [1600/60000 (3%)]\tLoss: 1.564868\n",
      "Train Epoch: 0 [1700/60000 (3%)]\tLoss: 1.633721\n",
      "Train Epoch: 0 [1800/60000 (3%)]\tLoss: 1.592878\n",
      "Train Epoch: 0 [1900/60000 (3%)]\tLoss: 1.666539\n",
      "Train Epoch: 0 [2000/60000 (3%)]\tLoss: 1.321927\n",
      "Train Epoch: 0 [2100/60000 (4%)]\tLoss: 1.493183\n",
      "Train Epoch: 0 [2200/60000 (4%)]\tLoss: 1.593193\n",
      "Train Epoch: 0 [2300/60000 (4%)]\tLoss: 1.468115\n",
      "Train Epoch: 0 [2400/60000 (4%)]\tLoss: 1.470624\n",
      "Train Epoch: 0 [2500/60000 (4%)]\tLoss: 1.540528\n",
      "Train Epoch: 0 [2600/60000 (4%)]\tLoss: 1.259494\n",
      "Train Epoch: 0 [2700/60000 (4%)]\tLoss: 1.473153\n",
      "Train Epoch: 0 [2800/60000 (5%)]\tLoss: 1.167909\n",
      "Train Epoch: 0 [2900/60000 (5%)]\tLoss: 1.274101\n",
      "Train Epoch: 0 [3000/60000 (5%)]\tLoss: 1.350046\n",
      "Train Epoch: 0 [3100/60000 (5%)]\tLoss: 1.233246\n",
      "Train Epoch: 0 [3200/60000 (5%)]\tLoss: 1.315604\n",
      "Train Epoch: 0 [3300/60000 (6%)]\tLoss: 1.061039\n",
      "Train Epoch: 0 [3400/60000 (6%)]\tLoss: 1.493624\n",
      "Train Epoch: 0 [3500/60000 (6%)]\tLoss: 1.093615\n",
      "Train Epoch: 0 [3600/60000 (6%)]\tLoss: 0.932629\n",
      "Train Epoch: 0 [3700/60000 (6%)]\tLoss: 1.122726\n",
      "Train Epoch: 0 [3800/60000 (6%)]\tLoss: 0.932054\n",
      "Train Epoch: 0 [3900/60000 (6%)]\tLoss: 1.040746\n",
      "Train Epoch: 0 [4000/60000 (7%)]\tLoss: 0.739334\n",
      "Train Epoch: 0 [4100/60000 (7%)]\tLoss: 1.165518\n",
      "Train Epoch: 0 [4200/60000 (7%)]\tLoss: 1.156283\n",
      "Train Epoch: 0 [4300/60000 (7%)]\tLoss: 0.871505\n",
      "Train Epoch: 0 [4400/60000 (7%)]\tLoss: 1.171277\n",
      "Train Epoch: 0 [4500/60000 (8%)]\tLoss: 0.934725\n",
      "Train Epoch: 0 [4600/60000 (8%)]\tLoss: 0.635216\n",
      "Train Epoch: 0 [4700/60000 (8%)]\tLoss: 0.696549\n",
      "Train Epoch: 0 [4800/60000 (8%)]\tLoss: 0.950773\n",
      "Train Epoch: 0 [4900/60000 (8%)]\tLoss: 0.841525\n",
      "Train Epoch: 0 [5000/60000 (8%)]\tLoss: 0.954257\n",
      "Train Epoch: 0 [5100/60000 (8%)]\tLoss: 1.024793\n",
      "Train Epoch: 0 [5200/60000 (9%)]\tLoss: 0.697610\n",
      "Train Epoch: 0 [5300/60000 (9%)]\tLoss: 0.965988\n",
      "Train Epoch: 0 [5400/60000 (9%)]\tLoss: 0.805515\n",
      "Train Epoch: 0 [5500/60000 (9%)]\tLoss: 0.846462\n",
      "Train Epoch: 0 [5600/60000 (9%)]\tLoss: 0.639847\n",
      "Train Epoch: 0 [5700/60000 (10%)]\tLoss: 0.824659\n",
      "Train Epoch: 0 [5800/60000 (10%)]\tLoss: 0.712895\n",
      "Train Epoch: 0 [5900/60000 (10%)]\tLoss: 0.800187\n",
      "Train Epoch: 0 [6000/60000 (10%)]\tLoss: 0.758362\n",
      "Train Epoch: 0 [6100/60000 (10%)]\tLoss: 0.453248\n",
      "Train Epoch: 0 [6200/60000 (10%)]\tLoss: 1.096359\n",
      "Train Epoch: 0 [6300/60000 (10%)]\tLoss: 0.873738\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 0.906747\n",
      "Train Epoch: 0 [6500/60000 (11%)]\tLoss: 0.519208\n",
      "Train Epoch: 0 [6600/60000 (11%)]\tLoss: 0.504902\n",
      "Train Epoch: 0 [6700/60000 (11%)]\tLoss: 0.538054\n",
      "Train Epoch: 0 [6800/60000 (11%)]\tLoss: 0.637407\n",
      "Train Epoch: 0 [6900/60000 (12%)]\tLoss: 0.442706\n",
      "Train Epoch: 0 [7000/60000 (12%)]\tLoss: 0.857845\n",
      "Train Epoch: 0 [7100/60000 (12%)]\tLoss: 0.340477\n",
      "Train Epoch: 0 [7200/60000 (12%)]\tLoss: 0.435577\n",
      "Train Epoch: 0 [7300/60000 (12%)]\tLoss: 0.787557\n",
      "Train Epoch: 0 [7400/60000 (12%)]\tLoss: 0.357104\n",
      "Train Epoch: 0 [7500/60000 (12%)]\tLoss: 0.477871\n",
      "Train Epoch: 0 [7600/60000 (13%)]\tLoss: 0.384616\n",
      "Train Epoch: 0 [7700/60000 (13%)]\tLoss: 1.006062\n",
      "Train Epoch: 0 [7800/60000 (13%)]\tLoss: 0.843846\n",
      "Train Epoch: 0 [7900/60000 (13%)]\tLoss: 0.454892\n",
      "Train Epoch: 0 [8000/60000 (13%)]\tLoss: 0.544284\n",
      "Train Epoch: 0 [8100/60000 (14%)]\tLoss: 0.369572\n",
      "Train Epoch: 0 [8200/60000 (14%)]\tLoss: 0.567585\n",
      "Train Epoch: 0 [8300/60000 (14%)]\tLoss: 1.017728\n",
      "Train Epoch: 0 [8400/60000 (14%)]\tLoss: 0.472057\n",
      "Train Epoch: 0 [8500/60000 (14%)]\tLoss: 0.281091\n",
      "Train Epoch: 0 [8600/60000 (14%)]\tLoss: 0.204311\n",
      "Train Epoch: 0 [8700/60000 (14%)]\tLoss: 0.745062\n",
      "Train Epoch: 0 [8800/60000 (15%)]\tLoss: 0.189455\n",
      "Train Epoch: 0 [8900/60000 (15%)]\tLoss: 0.350786\n",
      "Train Epoch: 0 [9000/60000 (15%)]\tLoss: 0.442799\n",
      "Train Epoch: 0 [9100/60000 (15%)]\tLoss: 0.247218\n",
      "Train Epoch: 0 [9200/60000 (15%)]\tLoss: 0.327925\n",
      "Train Epoch: 0 [9300/60000 (16%)]\tLoss: 0.606445\n",
      "Train Epoch: 0 [9400/60000 (16%)]\tLoss: 0.642775\n",
      "Train Epoch: 0 [9500/60000 (16%)]\tLoss: 0.468030\n",
      "Train Epoch: 0 [9600/60000 (16%)]\tLoss: 0.309456\n",
      "Train Epoch: 0 [9700/60000 (16%)]\tLoss: 1.390195\n",
      "Train Epoch: 0 [9800/60000 (16%)]\tLoss: 0.660774\n",
      "Train Epoch: 0 [9900/60000 (16%)]\tLoss: 0.354597\n",
      "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 0.459110\n",
      "Train Epoch: 0 [10100/60000 (17%)]\tLoss: 0.526600\n",
      "Train Epoch: 0 [10200/60000 (17%)]\tLoss: 0.312387\n",
      "Train Epoch: 0 [10300/60000 (17%)]\tLoss: 0.308790\n",
      "Train Epoch: 0 [10400/60000 (17%)]\tLoss: 0.835582\n",
      "Train Epoch: 0 [10500/60000 (18%)]\tLoss: 0.127651\n",
      "Train Epoch: 0 [10600/60000 (18%)]\tLoss: 0.634919\n",
      "Train Epoch: 0 [10700/60000 (18%)]\tLoss: 0.998483\n",
      "Train Epoch: 0 [10800/60000 (18%)]\tLoss: 0.253866\n",
      "Train Epoch: 0 [10900/60000 (18%)]\tLoss: 0.257896\n",
      "Train Epoch: 0 [11000/60000 (18%)]\tLoss: 0.157614\n",
      "Train Epoch: 0 [11100/60000 (18%)]\tLoss: 0.293313\n",
      "Train Epoch: 0 [11200/60000 (19%)]\tLoss: 0.141930\n",
      "Train Epoch: 0 [11300/60000 (19%)]\tLoss: 0.248786\n",
      "Train Epoch: 0 [11400/60000 (19%)]\tLoss: 0.320649\n",
      "Train Epoch: 0 [11500/60000 (19%)]\tLoss: 0.347326\n",
      "Train Epoch: 0 [11600/60000 (19%)]\tLoss: 0.804625\n",
      "Train Epoch: 0 [11700/60000 (20%)]\tLoss: 0.685084\n",
      "Train Epoch: 0 [11800/60000 (20%)]\tLoss: 0.441256\n",
      "Train Epoch: 0 [11900/60000 (20%)]\tLoss: 0.253506\n",
      "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.117435\n",
      "Train Epoch: 0 [12100/60000 (20%)]\tLoss: 0.279838\n",
      "Train Epoch: 0 [12200/60000 (20%)]\tLoss: 0.174447\n",
      "Train Epoch: 0 [12300/60000 (20%)]\tLoss: 0.164711\n",
      "Train Epoch: 0 [12400/60000 (21%)]\tLoss: 0.501165\n",
      "Train Epoch: 0 [12500/60000 (21%)]\tLoss: 0.308300\n",
      "Train Epoch: 0 [12600/60000 (21%)]\tLoss: 0.308106\n",
      "Train Epoch: 0 [12700/60000 (21%)]\tLoss: 0.442918\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.399043\n",
      "Train Epoch: 0 [12900/60000 (22%)]\tLoss: 0.259776\n",
      "Train Epoch: 0 [13000/60000 (22%)]\tLoss: 0.956361\n",
      "Train Epoch: 0 [13100/60000 (22%)]\tLoss: 0.144029\n",
      "Train Epoch: 0 [13200/60000 (22%)]\tLoss: 0.945436\n",
      "Train Epoch: 0 [13300/60000 (22%)]\tLoss: 0.144798\n",
      "Train Epoch: 0 [13400/60000 (22%)]\tLoss: 0.487416\n",
      "Train Epoch: 0 [13500/60000 (22%)]\tLoss: 0.290577\n",
      "Train Epoch: 0 [13600/60000 (23%)]\tLoss: 0.607748\n",
      "Train Epoch: 0 [13700/60000 (23%)]\tLoss: 0.252853\n",
      "Train Epoch: 0 [13800/60000 (23%)]\tLoss: 0.318215\n",
      "Train Epoch: 0 [13900/60000 (23%)]\tLoss: 0.147429\n",
      "Train Epoch: 0 [14000/60000 (23%)]\tLoss: 1.078661\n",
      "Train Epoch: 0 [14100/60000 (24%)]\tLoss: 0.157217\n",
      "Train Epoch: 0 [14200/60000 (24%)]\tLoss: 0.283726\n",
      "Train Epoch: 0 [14300/60000 (24%)]\tLoss: 0.260575\n",
      "Train Epoch: 0 [14400/60000 (24%)]\tLoss: 0.275870\n",
      "Train Epoch: 0 [14500/60000 (24%)]\tLoss: 0.171663\n",
      "Train Epoch: 0 [14600/60000 (24%)]\tLoss: 0.498894\n",
      "Train Epoch: 0 [14700/60000 (24%)]\tLoss: 0.460147\n",
      "Train Epoch: 0 [14800/60000 (25%)]\tLoss: 0.455638\n",
      "Train Epoch: 0 [14900/60000 (25%)]\tLoss: 0.494964\n",
      "Train Epoch: 0 [15000/60000 (25%)]\tLoss: 0.256785\n",
      "Train Epoch: 0 [15100/60000 (25%)]\tLoss: 0.355537\n",
      "Train Epoch: 0 [15200/60000 (25%)]\tLoss: 0.714256\n",
      "Train Epoch: 0 [15300/60000 (26%)]\tLoss: 0.544180\n",
      "Train Epoch: 0 [15400/60000 (26%)]\tLoss: 0.368742\n",
      "Train Epoch: 0 [15500/60000 (26%)]\tLoss: 0.574428\n",
      "Train Epoch: 0 [15600/60000 (26%)]\tLoss: 0.133082\n",
      "Train Epoch: 0 [15700/60000 (26%)]\tLoss: 0.404240\n",
      "Train Epoch: 0 [15800/60000 (26%)]\tLoss: 0.491165\n",
      "Train Epoch: 0 [15900/60000 (26%)]\tLoss: 0.225310\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 0.205935\n",
      "Train Epoch: 0 [16100/60000 (27%)]\tLoss: 0.187358\n",
      "Train Epoch: 0 [16200/60000 (27%)]\tLoss: 0.177978\n",
      "Train Epoch: 0 [16300/60000 (27%)]\tLoss: 0.618185\n",
      "Train Epoch: 0 [16400/60000 (27%)]\tLoss: 1.323100\n",
      "Train Epoch: 0 [16500/60000 (28%)]\tLoss: 0.536929\n",
      "Train Epoch: 0 [16600/60000 (28%)]\tLoss: 0.210586\n",
      "Train Epoch: 0 [16700/60000 (28%)]\tLoss: 0.258752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [16800/60000 (28%)]\tLoss: 0.369903\n",
      "Train Epoch: 0 [16900/60000 (28%)]\tLoss: 0.194702\n",
      "Train Epoch: 0 [17000/60000 (28%)]\tLoss: 0.591316\n",
      "Train Epoch: 0 [17100/60000 (28%)]\tLoss: 0.181977\n",
      "Train Epoch: 0 [17200/60000 (29%)]\tLoss: 0.251853\n",
      "Train Epoch: 0 [17300/60000 (29%)]\tLoss: 0.118936\n",
      "Train Epoch: 0 [17400/60000 (29%)]\tLoss: 0.171325\n",
      "Train Epoch: 0 [17500/60000 (29%)]\tLoss: 0.507318\n",
      "Train Epoch: 0 [17600/60000 (29%)]\tLoss: 0.162596\n",
      "Train Epoch: 0 [17700/60000 (30%)]\tLoss: 0.236774\n",
      "Train Epoch: 0 [17800/60000 (30%)]\tLoss: 0.084678\n",
      "Train Epoch: 0 [17900/60000 (30%)]\tLoss: 0.410082\n",
      "Train Epoch: 0 [18000/60000 (30%)]\tLoss: 0.098930\n",
      "Train Epoch: 0 [18100/60000 (30%)]\tLoss: 0.237558\n",
      "Train Epoch: 0 [18200/60000 (30%)]\tLoss: 0.174550\n",
      "Train Epoch: 0 [18300/60000 (30%)]\tLoss: 0.144266\n",
      "Train Epoch: 0 [18400/60000 (31%)]\tLoss: 0.091088\n",
      "Train Epoch: 0 [18500/60000 (31%)]\tLoss: 0.310711\n",
      "Train Epoch: 0 [18600/60000 (31%)]\tLoss: 0.130161\n",
      "Train Epoch: 0 [18700/60000 (31%)]\tLoss: 0.219356\n",
      "Train Epoch: 0 [18800/60000 (31%)]\tLoss: 0.078820\n",
      "Train Epoch: 0 [18900/60000 (32%)]\tLoss: 0.486013\n",
      "Train Epoch: 0 [19000/60000 (32%)]\tLoss: 0.209875\n",
      "Train Epoch: 0 [19100/60000 (32%)]\tLoss: 0.362843\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.422258\n",
      "Train Epoch: 0 [19300/60000 (32%)]\tLoss: 0.133310\n",
      "Train Epoch: 0 [19400/60000 (32%)]\tLoss: 0.456851\n",
      "Train Epoch: 0 [19500/60000 (32%)]\tLoss: 0.654014\n",
      "Train Epoch: 0 [19600/60000 (33%)]\tLoss: 0.263341\n",
      "Train Epoch: 0 [19700/60000 (33%)]\tLoss: 0.257894\n",
      "Train Epoch: 0 [19800/60000 (33%)]\tLoss: 0.112394\n",
      "Train Epoch: 0 [19900/60000 (33%)]\tLoss: 0.045309\n",
      "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 0.158150\n",
      "Train Epoch: 0 [20100/60000 (34%)]\tLoss: 0.052336\n",
      "Train Epoch: 0 [20200/60000 (34%)]\tLoss: 0.097190\n",
      "Train Epoch: 0 [20300/60000 (34%)]\tLoss: 0.100796\n",
      "Train Epoch: 0 [20400/60000 (34%)]\tLoss: 0.067769\n",
      "Train Epoch: 0 [20500/60000 (34%)]\tLoss: 0.139025\n",
      "Train Epoch: 0 [20600/60000 (34%)]\tLoss: 0.302887\n",
      "Train Epoch: 0 [20700/60000 (34%)]\tLoss: 0.211483\n",
      "Train Epoch: 0 [20800/60000 (35%)]\tLoss: 0.079194\n",
      "Train Epoch: 0 [20900/60000 (35%)]\tLoss: 0.427049\n",
      "Train Epoch: 0 [21000/60000 (35%)]\tLoss: 0.159418\n",
      "Train Epoch: 0 [21100/60000 (35%)]\tLoss: 0.177972\n",
      "Train Epoch: 0 [21200/60000 (35%)]\tLoss: 0.047215\n",
      "Train Epoch: 0 [21300/60000 (36%)]\tLoss: 0.101628\n",
      "Train Epoch: 0 [21400/60000 (36%)]\tLoss: 0.400537\n",
      "Train Epoch: 0 [21500/60000 (36%)]\tLoss: 0.168571\n",
      "Train Epoch: 0 [21600/60000 (36%)]\tLoss: 0.804517\n",
      "Train Epoch: 0 [21700/60000 (36%)]\tLoss: 0.207300\n",
      "Train Epoch: 0 [21800/60000 (36%)]\tLoss: 0.082810\n",
      "Train Epoch: 0 [21900/60000 (36%)]\tLoss: 0.239592\n",
      "Train Epoch: 0 [22000/60000 (37%)]\tLoss: 0.883979\n",
      "Train Epoch: 0 [22100/60000 (37%)]\tLoss: 0.428763\n",
      "Train Epoch: 0 [22200/60000 (37%)]\tLoss: 0.081032\n",
      "Train Epoch: 0 [22300/60000 (37%)]\tLoss: 0.057756\n",
      "Train Epoch: 0 [22400/60000 (37%)]\tLoss: 0.271918\n",
      "Train Epoch: 0 [22500/60000 (38%)]\tLoss: 0.045974\n",
      "Train Epoch: 0 [22600/60000 (38%)]\tLoss: 0.553284\n",
      "Train Epoch: 0 [22700/60000 (38%)]\tLoss: 0.159972\n",
      "Train Epoch: 0 [22800/60000 (38%)]\tLoss: 0.607145\n",
      "Train Epoch: 0 [22900/60000 (38%)]\tLoss: 0.137395\n",
      "Train Epoch: 0 [23000/60000 (38%)]\tLoss: 0.246575\n",
      "Train Epoch: 0 [23100/60000 (38%)]\tLoss: 0.157061\n",
      "Train Epoch: 0 [23200/60000 (39%)]\tLoss: 0.580081\n",
      "Train Epoch: 0 [23300/60000 (39%)]\tLoss: 0.154294\n",
      "Train Epoch: 0 [23400/60000 (39%)]\tLoss: 0.179849\n",
      "Train Epoch: 0 [23500/60000 (39%)]\tLoss: 0.067593\n",
      "Train Epoch: 0 [23600/60000 (39%)]\tLoss: 0.396154\n",
      "Train Epoch: 0 [23700/60000 (40%)]\tLoss: 0.043661\n",
      "Train Epoch: 0 [23800/60000 (40%)]\tLoss: 0.131437\n",
      "Train Epoch: 0 [23900/60000 (40%)]\tLoss: 0.141697\n",
      "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.054768\n",
      "Train Epoch: 0 [24100/60000 (40%)]\tLoss: 0.051091\n",
      "Train Epoch: 0 [24200/60000 (40%)]\tLoss: 0.052727\n",
      "Train Epoch: 0 [24300/60000 (40%)]\tLoss: 0.264928\n",
      "Train Epoch: 0 [24400/60000 (41%)]\tLoss: 0.229663\n",
      "Train Epoch: 0 [24500/60000 (41%)]\tLoss: 0.047975\n",
      "Train Epoch: 0 [24600/60000 (41%)]\tLoss: 0.386551\n",
      "Train Epoch: 0 [24700/60000 (41%)]\tLoss: 0.210533\n",
      "Train Epoch: 0 [24800/60000 (41%)]\tLoss: 0.212708\n",
      "Train Epoch: 0 [24900/60000 (42%)]\tLoss: 0.042740\n",
      "Train Epoch: 0 [25000/60000 (42%)]\tLoss: 0.303231\n",
      "Train Epoch: 0 [25100/60000 (42%)]\tLoss: 0.086816\n",
      "Train Epoch: 0 [25200/60000 (42%)]\tLoss: 0.075774\n",
      "Train Epoch: 0 [25300/60000 (42%)]\tLoss: 0.288762\n",
      "Train Epoch: 0 [25400/60000 (42%)]\tLoss: 0.170118\n",
      "Train Epoch: 0 [25500/60000 (42%)]\tLoss: 0.244953\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.128768\n",
      "Train Epoch: 0 [25700/60000 (43%)]\tLoss: 0.223046\n",
      "Train Epoch: 0 [25800/60000 (43%)]\tLoss: 0.153039\n",
      "Train Epoch: 0 [25900/60000 (43%)]\tLoss: 0.118018\n",
      "Train Epoch: 0 [26000/60000 (43%)]\tLoss: 0.041454\n",
      "Train Epoch: 0 [26100/60000 (44%)]\tLoss: 0.104267\n",
      "Train Epoch: 0 [26200/60000 (44%)]\tLoss: 0.169716\n",
      "Train Epoch: 0 [26300/60000 (44%)]\tLoss: 0.208648\n",
      "Train Epoch: 0 [26400/60000 (44%)]\tLoss: 0.300753\n",
      "Train Epoch: 0 [26500/60000 (44%)]\tLoss: 0.620418\n",
      "Train Epoch: 0 [26600/60000 (44%)]\tLoss: 0.485888\n",
      "Train Epoch: 0 [26700/60000 (44%)]\tLoss: 0.724968\n",
      "Train Epoch: 0 [26800/60000 (45%)]\tLoss: 0.306080\n",
      "Train Epoch: 0 [26900/60000 (45%)]\tLoss: 0.284149\n",
      "Train Epoch: 0 [27000/60000 (45%)]\tLoss: 0.278220\n",
      "Train Epoch: 0 [27100/60000 (45%)]\tLoss: 0.613050\n",
      "Train Epoch: 0 [27200/60000 (45%)]\tLoss: 0.210423\n",
      "Train Epoch: 0 [27300/60000 (46%)]\tLoss: 0.256896\n",
      "Train Epoch: 0 [27400/60000 (46%)]\tLoss: 0.106830\n",
      "Train Epoch: 0 [27500/60000 (46%)]\tLoss: 0.294108\n",
      "Train Epoch: 0 [27600/60000 (46%)]\tLoss: 0.122735\n",
      "Train Epoch: 0 [27700/60000 (46%)]\tLoss: 0.038804\n",
      "Train Epoch: 0 [27800/60000 (46%)]\tLoss: 0.105925\n",
      "Train Epoch: 0 [27900/60000 (46%)]\tLoss: 0.126647\n",
      "Train Epoch: 0 [28000/60000 (47%)]\tLoss: 0.061409\n",
      "Train Epoch: 0 [28100/60000 (47%)]\tLoss: 0.104526\n",
      "Train Epoch: 0 [28200/60000 (47%)]\tLoss: 0.046674\n",
      "Train Epoch: 0 [28300/60000 (47%)]\tLoss: 0.113508\n",
      "Train Epoch: 0 [28400/60000 (47%)]\tLoss: 0.155823\n",
      "Train Epoch: 0 [28500/60000 (48%)]\tLoss: 1.600825\n",
      "Train Epoch: 0 [28600/60000 (48%)]\tLoss: 0.131423\n",
      "Train Epoch: 0 [28700/60000 (48%)]\tLoss: 0.112930\n",
      "Train Epoch: 0 [28800/60000 (48%)]\tLoss: 0.525907\n",
      "Train Epoch: 0 [28900/60000 (48%)]\tLoss: 0.104962\n",
      "Train Epoch: 0 [29000/60000 (48%)]\tLoss: 0.065404\n",
      "Train Epoch: 0 [29100/60000 (48%)]\tLoss: 0.387251\n",
      "Train Epoch: 0 [29200/60000 (49%)]\tLoss: 0.184138\n",
      "Train Epoch: 0 [29300/60000 (49%)]\tLoss: 0.457778\n",
      "Train Epoch: 0 [29400/60000 (49%)]\tLoss: 0.127204\n",
      "Train Epoch: 0 [29500/60000 (49%)]\tLoss: 0.315800\n",
      "Train Epoch: 0 [29600/60000 (49%)]\tLoss: 0.078924\n",
      "Train Epoch: 0 [29700/60000 (50%)]\tLoss: 0.143271\n",
      "Train Epoch: 0 [29800/60000 (50%)]\tLoss: 0.038671\n",
      "Train Epoch: 0 [29900/60000 (50%)]\tLoss: 0.082842\n",
      "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 0.620799\n",
      "Train Epoch: 0 [30100/60000 (50%)]\tLoss: 0.043772\n",
      "Train Epoch: 0 [30200/60000 (50%)]\tLoss: 0.216857\n",
      "Train Epoch: 0 [30300/60000 (50%)]\tLoss: 0.045366\n",
      "Train Epoch: 0 [30400/60000 (51%)]\tLoss: 0.399474\n",
      "Train Epoch: 0 [30500/60000 (51%)]\tLoss: 0.048775\n",
      "Train Epoch: 0 [30600/60000 (51%)]\tLoss: 0.038310\n",
      "Train Epoch: 0 [30700/60000 (51%)]\tLoss: 0.136784\n",
      "Train Epoch: 0 [30800/60000 (51%)]\tLoss: 0.205366\n",
      "Train Epoch: 0 [30900/60000 (52%)]\tLoss: 0.271809\n",
      "Train Epoch: 0 [31000/60000 (52%)]\tLoss: 0.247671\n",
      "Train Epoch: 0 [31100/60000 (52%)]\tLoss: 0.163723\n",
      "Train Epoch: 0 [31200/60000 (52%)]\tLoss: 0.101224\n",
      "Train Epoch: 0 [31300/60000 (52%)]\tLoss: 0.098537\n",
      "Train Epoch: 0 [31400/60000 (52%)]\tLoss: 0.077236\n",
      "Train Epoch: 0 [31500/60000 (52%)]\tLoss: 0.034336\n",
      "Train Epoch: 0 [31600/60000 (53%)]\tLoss: 0.102873\n",
      "Train Epoch: 0 [31700/60000 (53%)]\tLoss: 0.027225\n",
      "Train Epoch: 0 [31800/60000 (53%)]\tLoss: 0.159469\n",
      "Train Epoch: 0 [31900/60000 (53%)]\tLoss: 0.153740\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.735058\n",
      "Train Epoch: 0 [32100/60000 (54%)]\tLoss: 0.328252\n",
      "Train Epoch: 0 [32200/60000 (54%)]\tLoss: 0.241304\n",
      "Train Epoch: 0 [32300/60000 (54%)]\tLoss: 0.268228\n",
      "Train Epoch: 0 [32400/60000 (54%)]\tLoss: 0.232621\n",
      "Train Epoch: 0 [32500/60000 (54%)]\tLoss: 0.491583\n",
      "Train Epoch: 0 [32600/60000 (54%)]\tLoss: 0.163699\n",
      "Train Epoch: 0 [32700/60000 (54%)]\tLoss: 0.398624\n",
      "Train Epoch: 0 [32800/60000 (55%)]\tLoss: 0.044096\n",
      "Train Epoch: 0 [32900/60000 (55%)]\tLoss: 0.152180\n",
      "Train Epoch: 0 [33000/60000 (55%)]\tLoss: 0.451275\n",
      "Train Epoch: 0 [33100/60000 (55%)]\tLoss: 0.249409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [33200/60000 (55%)]\tLoss: 0.039012\n",
      "Train Epoch: 0 [33300/60000 (56%)]\tLoss: 0.111756\n",
      "Train Epoch: 0 [33400/60000 (56%)]\tLoss: 0.099388\n",
      "Train Epoch: 0 [33500/60000 (56%)]\tLoss: 0.111482\n",
      "Train Epoch: 0 [33600/60000 (56%)]\tLoss: 0.065368\n",
      "Train Epoch: 0 [33700/60000 (56%)]\tLoss: 0.474396\n",
      "Train Epoch: 0 [33800/60000 (56%)]\tLoss: 0.078498\n",
      "Train Epoch: 0 [33900/60000 (56%)]\tLoss: 0.437569\n",
      "Train Epoch: 0 [34000/60000 (57%)]\tLoss: 0.214468\n",
      "Train Epoch: 0 [34100/60000 (57%)]\tLoss: 0.032019\n",
      "Train Epoch: 0 [34200/60000 (57%)]\tLoss: 0.279226\n",
      "Train Epoch: 0 [34300/60000 (57%)]\tLoss: 0.318686\n",
      "Train Epoch: 0 [34400/60000 (57%)]\tLoss: 0.252998\n",
      "Train Epoch: 0 [34500/60000 (58%)]\tLoss: 0.181469\n",
      "Train Epoch: 0 [34600/60000 (58%)]\tLoss: 0.066154\n",
      "Train Epoch: 0 [34700/60000 (58%)]\tLoss: 0.415548\n",
      "Train Epoch: 0 [34800/60000 (58%)]\tLoss: 0.319727\n",
      "Train Epoch: 0 [34900/60000 (58%)]\tLoss: 1.012954\n",
      "Train Epoch: 0 [35000/60000 (58%)]\tLoss: 0.194944\n",
      "Train Epoch: 0 [35100/60000 (58%)]\tLoss: 0.230481\n",
      "Train Epoch: 0 [35200/60000 (59%)]\tLoss: 0.024317\n",
      "Train Epoch: 0 [35300/60000 (59%)]\tLoss: 0.479124\n",
      "Train Epoch: 0 [35400/60000 (59%)]\tLoss: 0.089193\n",
      "Train Epoch: 0 [35500/60000 (59%)]\tLoss: 0.316030\n",
      "Train Epoch: 0 [35600/60000 (59%)]\tLoss: 0.064753\n",
      "Train Epoch: 0 [35700/60000 (60%)]\tLoss: 0.289448\n",
      "Train Epoch: 0 [35800/60000 (60%)]\tLoss: 0.040080\n",
      "Train Epoch: 0 [35900/60000 (60%)]\tLoss: 0.016277\n",
      "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.076879\n",
      "Train Epoch: 0 [36100/60000 (60%)]\tLoss: 0.028214\n",
      "Train Epoch: 0 [36200/60000 (60%)]\tLoss: 0.009837\n",
      "Train Epoch: 0 [36300/60000 (60%)]\tLoss: 0.033562\n",
      "Train Epoch: 0 [36400/60000 (61%)]\tLoss: 0.124710\n",
      "Train Epoch: 0 [36500/60000 (61%)]\tLoss: 0.529866\n",
      "Train Epoch: 0 [36600/60000 (61%)]\tLoss: 0.333113\n",
      "Train Epoch: 0 [36700/60000 (61%)]\tLoss: 0.112078\n",
      "Train Epoch: 0 [36800/60000 (61%)]\tLoss: 0.020404\n",
      "Train Epoch: 0 [36900/60000 (62%)]\tLoss: 0.030653\n",
      "Train Epoch: 0 [37000/60000 (62%)]\tLoss: 0.088407\n",
      "Train Epoch: 0 [37100/60000 (62%)]\tLoss: 0.079319\n",
      "Train Epoch: 0 [37200/60000 (62%)]\tLoss: 0.127268\n",
      "Train Epoch: 0 [37300/60000 (62%)]\tLoss: 0.069605\n",
      "Train Epoch: 0 [37400/60000 (62%)]\tLoss: 0.338520\n",
      "Train Epoch: 0 [37500/60000 (62%)]\tLoss: 0.113312\n",
      "Train Epoch: 0 [37600/60000 (63%)]\tLoss: 0.388013\n",
      "Train Epoch: 0 [37700/60000 (63%)]\tLoss: 0.321731\n",
      "Train Epoch: 0 [37800/60000 (63%)]\tLoss: 0.067931\n",
      "Train Epoch: 0 [37900/60000 (63%)]\tLoss: 0.025940\n",
      "Train Epoch: 0 [38000/60000 (63%)]\tLoss: 0.056677\n",
      "Train Epoch: 0 [38100/60000 (64%)]\tLoss: 0.052209\n",
      "Train Epoch: 0 [38200/60000 (64%)]\tLoss: 0.017877\n",
      "Train Epoch: 0 [38300/60000 (64%)]\tLoss: 0.100869\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.045773\n",
      "Train Epoch: 0 [38500/60000 (64%)]\tLoss: 0.122126\n",
      "Train Epoch: 0 [38600/60000 (64%)]\tLoss: 0.062220\n",
      "Train Epoch: 0 [38700/60000 (64%)]\tLoss: 0.784057\n",
      "Train Epoch: 0 [38800/60000 (65%)]\tLoss: 0.055250\n",
      "Train Epoch: 0 [38900/60000 (65%)]\tLoss: 0.054687\n",
      "Train Epoch: 0 [39000/60000 (65%)]\tLoss: 0.388918\n",
      "Train Epoch: 0 [39100/60000 (65%)]\tLoss: 0.279707\n",
      "Train Epoch: 0 [39200/60000 (65%)]\tLoss: 0.196766\n",
      "Train Epoch: 0 [39300/60000 (66%)]\tLoss: 0.097630\n",
      "Train Epoch: 0 [39400/60000 (66%)]\tLoss: 0.032779\n",
      "Train Epoch: 0 [39500/60000 (66%)]\tLoss: 0.493223\n",
      "Train Epoch: 0 [39600/60000 (66%)]\tLoss: 0.319196\n",
      "Train Epoch: 0 [39700/60000 (66%)]\tLoss: 0.019732\n",
      "Train Epoch: 0 [39800/60000 (66%)]\tLoss: 0.419767\n",
      "Train Epoch: 0 [39900/60000 (66%)]\tLoss: 0.087250\n",
      "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 0.018934\n",
      "Train Epoch: 0 [40100/60000 (67%)]\tLoss: 0.209338\n",
      "Train Epoch: 0 [40200/60000 (67%)]\tLoss: 0.031883\n",
      "Train Epoch: 0 [40300/60000 (67%)]\tLoss: 0.029113\n",
      "Train Epoch: 0 [40400/60000 (67%)]\tLoss: 0.022375\n",
      "Train Epoch: 0 [40500/60000 (68%)]\tLoss: 0.445344\n",
      "Train Epoch: 0 [40600/60000 (68%)]\tLoss: 0.069596\n",
      "Train Epoch: 0 [40700/60000 (68%)]\tLoss: 0.089164\n",
      "Train Epoch: 0 [40800/60000 (68%)]\tLoss: 0.028414\n",
      "Train Epoch: 0 [40900/60000 (68%)]\tLoss: 0.128295\n",
      "Train Epoch: 0 [41000/60000 (68%)]\tLoss: 0.127072\n",
      "Train Epoch: 0 [41100/60000 (68%)]\tLoss: 0.072440\n",
      "Train Epoch: 0 [41200/60000 (69%)]\tLoss: 0.172801\n",
      "Train Epoch: 0 [41300/60000 (69%)]\tLoss: 0.306346\n",
      "Train Epoch: 0 [41400/60000 (69%)]\tLoss: 0.021254\n",
      "Train Epoch: 0 [41500/60000 (69%)]\tLoss: 0.015642\n",
      "Train Epoch: 0 [41600/60000 (69%)]\tLoss: 0.022337\n",
      "Train Epoch: 0 [41700/60000 (70%)]\tLoss: 0.019773\n",
      "Train Epoch: 0 [41800/60000 (70%)]\tLoss: 0.100245\n",
      "Train Epoch: 0 [41900/60000 (70%)]\tLoss: 0.172136\n",
      "Train Epoch: 0 [42000/60000 (70%)]\tLoss: 0.121588\n",
      "Train Epoch: 0 [42100/60000 (70%)]\tLoss: 0.011807\n",
      "Train Epoch: 0 [42200/60000 (70%)]\tLoss: 0.075848\n",
      "Train Epoch: 0 [42300/60000 (70%)]\tLoss: 0.201004\n",
      "Train Epoch: 0 [42400/60000 (71%)]\tLoss: 0.022098\n",
      "Train Epoch: 0 [42500/60000 (71%)]\tLoss: 0.042740\n",
      "Train Epoch: 0 [42600/60000 (71%)]\tLoss: 0.167207\n",
      "Train Epoch: 0 [42700/60000 (71%)]\tLoss: 0.218760\n",
      "Train Epoch: 0 [42800/60000 (71%)]\tLoss: 0.260206\n",
      "Train Epoch: 0 [42900/60000 (72%)]\tLoss: 0.082422\n",
      "Train Epoch: 0 [43000/60000 (72%)]\tLoss: 0.076292\n",
      "Train Epoch: 0 [43100/60000 (72%)]\tLoss: 0.017721\n",
      "Train Epoch: 0 [43200/60000 (72%)]\tLoss: 0.062035\n",
      "Train Epoch: 0 [43300/60000 (72%)]\tLoss: 0.017703\n",
      "Train Epoch: 0 [43400/60000 (72%)]\tLoss: 0.029737\n",
      "Train Epoch: 0 [43500/60000 (72%)]\tLoss: 0.043182\n",
      "Train Epoch: 0 [43600/60000 (73%)]\tLoss: 0.013817\n",
      "Train Epoch: 0 [43700/60000 (73%)]\tLoss: 0.298665\n",
      "Train Epoch: 0 [43800/60000 (73%)]\tLoss: 0.087851\n",
      "Train Epoch: 0 [43900/60000 (73%)]\tLoss: 0.231552\n",
      "Train Epoch: 0 [44000/60000 (73%)]\tLoss: 0.049960\n",
      "Train Epoch: 0 [44100/60000 (74%)]\tLoss: 0.178679\n",
      "Train Epoch: 0 [44200/60000 (74%)]\tLoss: 0.334873\n",
      "Train Epoch: 0 [44300/60000 (74%)]\tLoss: 0.060921\n",
      "Train Epoch: 0 [44400/60000 (74%)]\tLoss: 0.108675\n",
      "Train Epoch: 0 [44500/60000 (74%)]\tLoss: 0.251137\n",
      "Train Epoch: 0 [44600/60000 (74%)]\tLoss: 0.327078\n",
      "Train Epoch: 0 [44700/60000 (74%)]\tLoss: 0.012657\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.130689\n",
      "Train Epoch: 0 [44900/60000 (75%)]\tLoss: 0.137101\n",
      "Train Epoch: 0 [45000/60000 (75%)]\tLoss: 0.118389\n",
      "Train Epoch: 0 [45100/60000 (75%)]\tLoss: 0.186097\n",
      "Train Epoch: 0 [45200/60000 (75%)]\tLoss: 0.053734\n",
      "Train Epoch: 0 [45300/60000 (76%)]\tLoss: 0.086889\n",
      "Train Epoch: 0 [45400/60000 (76%)]\tLoss: 0.099214\n",
      "Train Epoch: 0 [45500/60000 (76%)]\tLoss: 0.018187\n",
      "Train Epoch: 0 [45600/60000 (76%)]\tLoss: 0.061525\n",
      "Train Epoch: 0 [45700/60000 (76%)]\tLoss: 0.084097\n",
      "Train Epoch: 0 [45800/60000 (76%)]\tLoss: 0.065907\n",
      "Train Epoch: 0 [45900/60000 (76%)]\tLoss: 0.837008\n",
      "Train Epoch: 0 [46000/60000 (77%)]\tLoss: 0.078699\n",
      "Train Epoch: 0 [46100/60000 (77%)]\tLoss: 0.140689\n",
      "Train Epoch: 0 [46200/60000 (77%)]\tLoss: 0.027880\n",
      "Train Epoch: 0 [46300/60000 (77%)]\tLoss: 0.418374\n",
      "Train Epoch: 0 [46400/60000 (77%)]\tLoss: 0.415842\n",
      "Train Epoch: 0 [46500/60000 (78%)]\tLoss: 0.110460\n",
      "Train Epoch: 0 [46600/60000 (78%)]\tLoss: 0.625117\n",
      "Train Epoch: 0 [46700/60000 (78%)]\tLoss: 0.335136\n",
      "Train Epoch: 0 [46800/60000 (78%)]\tLoss: 0.236181\n",
      "Train Epoch: 0 [46900/60000 (78%)]\tLoss: 0.566674\n",
      "Train Epoch: 0 [47000/60000 (78%)]\tLoss: 0.362291\n",
      "Train Epoch: 0 [47100/60000 (78%)]\tLoss: 0.255755\n",
      "Train Epoch: 0 [47200/60000 (79%)]\tLoss: 0.107534\n",
      "Train Epoch: 0 [47300/60000 (79%)]\tLoss: 0.084216\n",
      "Train Epoch: 0 [47400/60000 (79%)]\tLoss: 0.255172\n",
      "Train Epoch: 0 [47500/60000 (79%)]\tLoss: 0.039045\n",
      "Train Epoch: 0 [47600/60000 (79%)]\tLoss: 0.134498\n",
      "Train Epoch: 0 [47700/60000 (80%)]\tLoss: 0.036189\n",
      "Train Epoch: 0 [47800/60000 (80%)]\tLoss: 0.017593\n",
      "Train Epoch: 0 [47900/60000 (80%)]\tLoss: 0.044278\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.232243\n",
      "Train Epoch: 0 [48100/60000 (80%)]\tLoss: 0.020952\n",
      "Train Epoch: 0 [48200/60000 (80%)]\tLoss: 0.038332\n",
      "Train Epoch: 0 [48300/60000 (80%)]\tLoss: 0.033749\n",
      "Train Epoch: 0 [48400/60000 (81%)]\tLoss: 0.774437\n",
      "Train Epoch: 0 [48500/60000 (81%)]\tLoss: 0.030848\n",
      "Train Epoch: 0 [48600/60000 (81%)]\tLoss: 0.009549\n",
      "Train Epoch: 0 [48700/60000 (81%)]\tLoss: 0.093701\n",
      "Train Epoch: 0 [48800/60000 (81%)]\tLoss: 0.344070\n",
      "Train Epoch: 0 [48900/60000 (82%)]\tLoss: 0.027485\n",
      "Train Epoch: 0 [49000/60000 (82%)]\tLoss: 0.306054\n",
      "Train Epoch: 0 [49100/60000 (82%)]\tLoss: 0.070637\n",
      "Train Epoch: 0 [49200/60000 (82%)]\tLoss: 0.018124\n",
      "Train Epoch: 0 [49300/60000 (82%)]\tLoss: 0.015787\n",
      "Train Epoch: 0 [49400/60000 (82%)]\tLoss: 0.101916\n",
      "Train Epoch: 0 [49500/60000 (82%)]\tLoss: 0.457628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [49600/60000 (83%)]\tLoss: 0.025306\n",
      "Train Epoch: 0 [49700/60000 (83%)]\tLoss: 0.063864\n",
      "Train Epoch: 0 [49800/60000 (83%)]\tLoss: 0.047181\n",
      "Train Epoch: 0 [49900/60000 (83%)]\tLoss: 0.512740\n",
      "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 0.049323\n",
      "Train Epoch: 0 [50100/60000 (84%)]\tLoss: 0.014716\n",
      "Train Epoch: 0 [50200/60000 (84%)]\tLoss: 0.137178\n",
      "Train Epoch: 0 [50300/60000 (84%)]\tLoss: 0.146568\n",
      "Train Epoch: 0 [50400/60000 (84%)]\tLoss: 0.317670\n",
      "Train Epoch: 0 [50500/60000 (84%)]\tLoss: 0.105027\n",
      "Train Epoch: 0 [50600/60000 (84%)]\tLoss: 0.181544\n",
      "Train Epoch: 0 [50700/60000 (84%)]\tLoss: 0.102834\n",
      "Train Epoch: 0 [50800/60000 (85%)]\tLoss: 0.881015\n",
      "Train Epoch: 0 [50900/60000 (85%)]\tLoss: 0.226693\n",
      "Train Epoch: 0 [51000/60000 (85%)]\tLoss: 0.029441\n",
      "Train Epoch: 0 [51100/60000 (85%)]\tLoss: 0.031441\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.250143\n",
      "Train Epoch: 0 [51300/60000 (86%)]\tLoss: 0.119239\n",
      "Train Epoch: 0 [51400/60000 (86%)]\tLoss: 0.425060\n",
      "Train Epoch: 0 [51500/60000 (86%)]\tLoss: 0.117159\n",
      "Train Epoch: 0 [51600/60000 (86%)]\tLoss: 0.042246\n",
      "Train Epoch: 0 [51700/60000 (86%)]\tLoss: 0.166582\n",
      "Train Epoch: 0 [51800/60000 (86%)]\tLoss: 0.029735\n",
      "Train Epoch: 0 [51900/60000 (86%)]\tLoss: 0.080957\n",
      "Train Epoch: 0 [52000/60000 (87%)]\tLoss: 0.050277\n",
      "Train Epoch: 0 [52100/60000 (87%)]\tLoss: 0.073811\n",
      "Train Epoch: 0 [52200/60000 (87%)]\tLoss: 0.116502\n",
      "Train Epoch: 0 [52300/60000 (87%)]\tLoss: 0.085128\n",
      "Train Epoch: 0 [52400/60000 (87%)]\tLoss: 0.150864\n",
      "Train Epoch: 0 [52500/60000 (88%)]\tLoss: 0.049307\n",
      "Train Epoch: 0 [52600/60000 (88%)]\tLoss: 0.323106\n",
      "Train Epoch: 0 [52700/60000 (88%)]\tLoss: 0.031034\n",
      "Train Epoch: 0 [52800/60000 (88%)]\tLoss: 0.151877\n",
      "Train Epoch: 0 [52900/60000 (88%)]\tLoss: 0.081348\n",
      "Train Epoch: 0 [53000/60000 (88%)]\tLoss: 0.439042\n",
      "Train Epoch: 0 [53100/60000 (88%)]\tLoss: 0.266436\n",
      "Train Epoch: 0 [53200/60000 (89%)]\tLoss: 0.489569\n",
      "Train Epoch: 0 [53300/60000 (89%)]\tLoss: 0.052990\n",
      "Train Epoch: 0 [53400/60000 (89%)]\tLoss: 0.053127\n",
      "Train Epoch: 0 [53500/60000 (89%)]\tLoss: 0.031269\n",
      "Train Epoch: 0 [53600/60000 (89%)]\tLoss: 0.108624\n",
      "Train Epoch: 0 [53700/60000 (90%)]\tLoss: 0.097038\n",
      "Train Epoch: 0 [53800/60000 (90%)]\tLoss: 0.181731\n",
      "Train Epoch: 0 [53900/60000 (90%)]\tLoss: 0.105670\n",
      "Train Epoch: 0 [54000/60000 (90%)]\tLoss: 0.936158\n",
      "Train Epoch: 0 [54100/60000 (90%)]\tLoss: 0.107501\n",
      "Train Epoch: 0 [54200/60000 (90%)]\tLoss: 0.064770\n",
      "Train Epoch: 0 [54300/60000 (90%)]\tLoss: 0.128149\n",
      "Train Epoch: 0 [54400/60000 (91%)]\tLoss: 0.050714\n",
      "Train Epoch: 0 [54500/60000 (91%)]\tLoss: 0.637791\n",
      "Train Epoch: 0 [54600/60000 (91%)]\tLoss: 0.053277\n",
      "Train Epoch: 0 [54700/60000 (91%)]\tLoss: 0.053076\n",
      "Train Epoch: 0 [54800/60000 (91%)]\tLoss: 0.325084\n",
      "Train Epoch: 0 [54900/60000 (92%)]\tLoss: 0.018250\n",
      "Train Epoch: 0 [55000/60000 (92%)]\tLoss: 1.027325\n",
      "Train Epoch: 0 [55100/60000 (92%)]\tLoss: 0.206019\n",
      "Train Epoch: 0 [55200/60000 (92%)]\tLoss: 0.060926\n",
      "Train Epoch: 0 [55300/60000 (92%)]\tLoss: 0.061173\n",
      "Train Epoch: 0 [55400/60000 (92%)]\tLoss: 0.268972\n",
      "Train Epoch: 0 [55500/60000 (92%)]\tLoss: 0.105367\n",
      "Train Epoch: 0 [55600/60000 (93%)]\tLoss: 0.034139\n",
      "Train Epoch: 0 [55700/60000 (93%)]\tLoss: 0.169781\n",
      "Train Epoch: 0 [55800/60000 (93%)]\tLoss: 0.092404\n",
      "Train Epoch: 0 [55900/60000 (93%)]\tLoss: 0.094377\n",
      "Train Epoch: 0 [56000/60000 (93%)]\tLoss: 0.034215\n",
      "Train Epoch: 0 [56100/60000 (94%)]\tLoss: 0.454280\n",
      "Train Epoch: 0 [56200/60000 (94%)]\tLoss: 0.039867\n",
      "Train Epoch: 0 [56300/60000 (94%)]\tLoss: 0.033443\n",
      "Train Epoch: 0 [56400/60000 (94%)]\tLoss: 0.205113\n",
      "Train Epoch: 0 [56500/60000 (94%)]\tLoss: 0.044783\n",
      "Train Epoch: 0 [56600/60000 (94%)]\tLoss: 0.043154\n",
      "Train Epoch: 0 [56700/60000 (94%)]\tLoss: 0.262522\n",
      "Train Epoch: 0 [56800/60000 (95%)]\tLoss: 0.018851\n",
      "Train Epoch: 0 [56900/60000 (95%)]\tLoss: 0.021342\n",
      "Train Epoch: 0 [57000/60000 (95%)]\tLoss: 0.354489\n",
      "Train Epoch: 0 [57100/60000 (95%)]\tLoss: 0.058010\n",
      "Train Epoch: 0 [57200/60000 (95%)]\tLoss: 0.134423\n",
      "Train Epoch: 0 [57300/60000 (96%)]\tLoss: 0.067057\n",
      "Train Epoch: 0 [57400/60000 (96%)]\tLoss: 0.599800\n",
      "Train Epoch: 0 [57500/60000 (96%)]\tLoss: 0.095717\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.070612\n",
      "Train Epoch: 0 [57700/60000 (96%)]\tLoss: 0.027989\n",
      "Train Epoch: 0 [57800/60000 (96%)]\tLoss: 0.583741\n",
      "Train Epoch: 0 [57900/60000 (96%)]\tLoss: 0.544968\n",
      "Train Epoch: 0 [58000/60000 (97%)]\tLoss: 0.031938\n",
      "Train Epoch: 0 [58100/60000 (97%)]\tLoss: 0.174146\n",
      "Train Epoch: 0 [58200/60000 (97%)]\tLoss: 0.129024\n",
      "Train Epoch: 0 [58300/60000 (97%)]\tLoss: 0.178261\n",
      "Train Epoch: 0 [58400/60000 (97%)]\tLoss: 0.322725\n",
      "Train Epoch: 0 [58500/60000 (98%)]\tLoss: 0.154756\n",
      "Train Epoch: 0 [58600/60000 (98%)]\tLoss: 0.014602\n",
      "Train Epoch: 0 [58700/60000 (98%)]\tLoss: 0.016565\n",
      "Train Epoch: 0 [58800/60000 (98%)]\tLoss: 0.130499\n",
      "Train Epoch: 0 [58900/60000 (98%)]\tLoss: 0.064224\n",
      "Train Epoch: 0 [59000/60000 (98%)]\tLoss: 1.069856\n",
      "Train Epoch: 0 [59100/60000 (98%)]\tLoss: 0.031478\n",
      "Train Epoch: 0 [59200/60000 (99%)]\tLoss: 0.029520\n",
      "Train Epoch: 0 [59300/60000 (99%)]\tLoss: 0.339527\n",
      "Train Epoch: 0 [59400/60000 (99%)]\tLoss: 0.067280\n",
      "Train Epoch: 0 [59500/60000 (99%)]\tLoss: 0.019951\n",
      "Train Epoch: 0 [59600/60000 (99%)]\tLoss: 0.381267\n",
      "Train Epoch: 0 [59700/60000 (100%)]\tLoss: 0.045239\n",
      "Train Epoch: 0 [59800/60000 (100%)]\tLoss: 0.088177\n",
      "Train Epoch: 0 [59900/60000 (100%)]\tLoss: 0.033071\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)   # optimize all cnn parameters\n",
    "loss_func = nn.CrossEntropyLoss()   # the target label is not one-hotted\n",
    "# training and testing\n",
    "for epoch in range(EPOCH):\n",
    "    for step, (x, y) in enumerate(train_loader):   # divide batch data, normalize x when iterate train_loader\n",
    "        b_x = Variable(x)   # batch x\n",
    "        b_y = Variable(y)   # batch y\n",
    "\n",
    "        output = model(b_x)               # cnn output\n",
    "        loss = loss_func(output, b_y)   # cross entropy loss\n",
    "        optimizer.zero_grad()           # clear gradients for this training step\n",
    "        loss.backward()                 # backpropagation, compute gradients\n",
    "        optimizer.step()                # apply gradients\n",
    "\n",
    "        if step % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, step * len(b_x), len(train_loader.dataset),\n",
    "            100. * step / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0802, Accuracy: 9757/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "for data, target in testLoader:\n",
    "    data, target = Variable(data, volatile=True), Variable(target)\n",
    "    output = model(data)\n",
    "    test_loss += loss_func(output, target).data[0]\n",
    "    pred = output.data.max(1)[1] # get the index of the max log-probability\n",
    "    correct += pred.eq(target.data).cpu().sum()\n",
    "\n",
    "test_loss = test_loss\n",
    "test_loss /= len(testLoader) # loss function already averages over batch size\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(testLoader.dataset),\n",
    "    100. * correct / len(testLoader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_kernels(tensor, num_cols=3):\n",
    "\n",
    "    num_kernels = tensor.shape[0]\n",
    "    num_rows = 1+ num_kernels // num_cols\n",
    "    fig = plt.figure(figsize=(num_cols,num_rows))\n",
    "    for i in range(tensor.shape[0]):\n",
    "        ax1 = fig.add_subplot(num_rows,num_cols,i+1)\n",
    "        ax1.imshow(tensor[i][0],cmap='gray')\n",
    "        ax1.axis('off')\n",
    "        ax1.set_xticklabels([])\n",
    "        ax1.set_yticklabels([])\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "    plt.show()\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALwAAACCCAYAAAD8OaJ2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAAsRJREFUeJzt3LEuZHEYxuFvNhsX4TYUFHqFaCQ6F6CgM3RTKARzM2hc\njqi0WhRnqy0Wmzj5Toi8z1OOyTtnkl/+hZwzs2EYClL8+u4LgK8keKIIniiCJ4rgiSJ4ogieKIIn\niuCJInii/B7z5sVi0b4P4ezsrDtRVVXL5bK9MZ/PZ29f29/fb3/HjY2N7kRVVR0dHbU3hmF49x3/\n/qm7fXp62p2oqqqdnZ32xubm5v++5z+c8EQRPFEETxTBE0XwRBE8UQRPFMETRfBEETxRBE8UwRNF\n8EQRPFEET5RR98Ovrq62P/D29ra9UVV1cnLS3pjP5+9ee3p6au9OsVFVtVgsJtn5yOXlZXvj6upq\ngiupWl9fn2TnM5zwRBE8UQRPFMETRfBEETxRBE8UwRNF8EQRPFEETxTBE0XwRBE8UQRPFMETRfBE\nGfXE0/b2dvsDX15e2htVVRcXF5PsvLW1tdXeeHx8nOBKqs7PzyfZ+cj9/X174/n5eYIrqdrb22tv\n7O7ufup9TniiCJ4ogieK4IkieKIIniiCJ4rgiSJ4ogieKIIniuCJIniiCJ4ogieK4IkyG4bhu68B\nvowTniiCJ4rgiSJ4ogieKKN+puPm5qb9L521tbXuRFVVXV9ftzcODw9nE1wKP4gTniiCJ4rgiSJ4\nogieKIIniuCJIniiCJ4ogieK4IkieKIIniiCJ4rgiTLqVwseHh7a98MfHBx0J6qq6u7ubooZ98OH\nccITRfBEETxRBE8UwRNF8EQRPFEETxTBE0XwRBE8UQRPFMETRfBEETxRBE8UwRNl1BNPKysr7See\nXl9fuxNVVXV8fNzeWC6XnngK44QniuCJIniiCJ4ogieK4IkieKIIniiCJ4rgiSJ4ogieKIIniuCJ\nIniiCJ4oox4AgZ/OCU8UwRNF8EQRPFEETxTBE0XwRBE8UQRPFMET5Q+gGlkWupw6bAAAAABJRU5E\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f68ed7af110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mm= model.double()\n",
    "filters = mm.modules\n",
    "body_model = [i for i in mm.children()]\n",
    "body_model = body_model[0][3][3][4]\n",
    "layer1 = body_model\n",
    "tensor = layer1.weight.data.numpy()\n",
    "plot_kernels(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "body_model = [i for i in mm.children()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True)\n",
      "ReLU (inplace)\n",
      "_DenseBlock (\n",
      "  (denselayer1): _DenseLayer (\n",
      "    (norm.1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu.1): ReLU (inplace)\n",
      "    (conv.1): Conv2d(10, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer2): _DenseLayer (\n",
      "    (norm.1): BatchNorm2d(14, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu.1): ReLU (inplace)\n",
      "    (conv.1): Conv2d(14, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer3): _DenseLayer (\n",
      "    (norm.1): BatchNorm2d(18, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu.1): ReLU (inplace)\n",
      "    (conv.1): Conv2d(18, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer4): _DenseLayer (\n",
      "    (norm.1): BatchNorm2d(22, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu.1): ReLU (inplace)\n",
      "    (conv.1): Conv2d(22, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer5): _DenseLayer (\n",
      "    (norm.1): BatchNorm2d(26, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu.1): ReLU (inplace)\n",
      "    (conv.1): Conv2d(26, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer6): _DenseLayer (\n",
      "    (norm.1): BatchNorm2d(30, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu.1): ReLU (inplace)\n",
      "    (conv.1): Conv2d(30, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "_Transition (\n",
      "  (norm): BatchNorm2d(34, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (relu): ReLU (inplace)\n",
      "  (conv): Conv2d(34, 17, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (pool): AvgPool2d (\n",
      "  )\n",
      ")\n",
      "BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True)\n",
      "_DenseBlock (\n",
      "  (denselayer1): _DenseLayer (\n",
      "    (norm.1): BatchNorm2d(17, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu.1): ReLU (inplace)\n",
      "    (conv.1): Conv2d(17, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer2): _DenseLayer (\n",
      "    (norm.1): BatchNorm2d(21, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu.1): ReLU (inplace)\n",
      "    (conv.1): Conv2d(21, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer3): _DenseLayer (\n",
      "    (norm.1): BatchNorm2d(25, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu.1): ReLU (inplace)\n",
      "    (conv.1): Conv2d(25, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer4): _DenseLayer (\n",
      "    (norm.1): BatchNorm2d(29, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu.1): ReLU (inplace)\n",
      "    (conv.1): Conv2d(29, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer5): _DenseLayer (\n",
      "    (norm.1): BatchNorm2d(33, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu.1): ReLU (inplace)\n",
      "    (conv.1): Conv2d(33, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer6): _DenseLayer (\n",
      "    (norm.1): BatchNorm2d(37, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu.1): ReLU (inplace)\n",
      "    (conv.1): Conv2d(37, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "_Transition (\n",
      "  (norm): BatchNorm2d(41, eps=1e-05, momentum=0.1, affine=True)\n",
      "  (relu): ReLU (inplace)\n",
      "  (conv): Conv2d(41, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (pool): AvgPool2d (\n",
      "  )\n",
      ")\n",
      "BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True)\n",
      "_DenseBlock (\n",
      "  (denselayer1): _DenseLayer (\n",
      "    (norm.1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu.1): ReLU (inplace)\n",
      "    (conv.1): Conv2d(20, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer2): _DenseLayer (\n",
      "    (norm.1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu.1): ReLU (inplace)\n",
      "    (conv.1): Conv2d(24, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer3): _DenseLayer (\n",
      "    (norm.1): BatchNorm2d(28, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu.1): ReLU (inplace)\n",
      "    (conv.1): Conv2d(28, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer4): _DenseLayer (\n",
      "    (norm.1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu.1): ReLU (inplace)\n",
      "    (conv.1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer5): _DenseLayer (\n",
      "    (norm.1): BatchNorm2d(36, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu.1): ReLU (inplace)\n",
      "    (conv.1): Conv2d(36, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (denselayer6): _DenseLayer (\n",
      "    (norm.1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (relu.1): ReLU (inplace)\n",
      "    (conv.1): Conv2d(40, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (norm.2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True)\n",
      "    (conv.2): Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      ")\n",
      "BatchNorm2d(44, eps=1e-05, momentum=0.1, affine=True)\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "for i in body_model[0]:\n",
    "    c+=1\n",
    "    print i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(16, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body_model[0][3][3][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
